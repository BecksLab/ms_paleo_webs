---
title: "Methods for Reconstructing Paleo Food Webs"
author:
  - name: Tanya Strydom
    id: ts
    orcid: 0000-0001-6067-1349
    corresponding: true
    email: t.strydom@sheffield.ac.uk
    role: 
    - conceptualization: lead
    - methodology: supporting
    affiliation:
      - id: sheffield
        name: School of Biosciences, University of Sheffield, Sheffield, UK
  - name: Andrew P. Beckerman
    id: apb
    orcid: 0000-0002-7859-8394
    corresponding: false
    role: 
    - conceptualization: lead
    - methodology: supporting
    affiliations:
      - ref: sheffield
funding: "The author(s) received no specific funding for this work. Well they did I just haven't done the homework"
keywords:
  - food web
  - network construction
  - scientific ignorance
abstract: |
  TODO.
date: last-modified
bibliography: references.bib
citation:
  container-title: TBD
number-sections: true
---

# Why build paleo food webs?

-   Because its interesting?

-   Value in using hindcasting to aid in forecasting. *e.g.,* the Toarcian ms [@dunhill2024] shows how we can use these paleo communities to understand trophic-level responses to extinctions.

# How do we do it?

-   There is an evolving body of work that focuses on developing tools specifically for the task of predicting food webs.

-   There are a handful that have been developed specifically in the context of paleo settings *e.g.,* TODO but we can also talk about those that might have been developed/tested in contemporary settings but still have applicability in paleo ones.

-   Different underlying theory though

    -   Focus here on the idea of different 'currencies' but also aggregations - energy vs compatibility.

-   Insert brief overview of the different methods as they pertain to approach (so the T4T triangle)

-   Challenges we face (even in contemporary settings)?

    -   keep high level - I think the argument here should fall more in the data trade offs...

# Understanding how networks are different

It is important to be aware that networks can be configured in different ways depending on how the interactions are defined (Strydom, in prep). Basically we have metawebs, which represent *potential* interactions, and realised networks, which represent the subset of potential that are realised as a result of community and environmental context.

# Challenges specific to paleo communities/networks

Although there are a suite of tools and methods that have been developed to predict species interactions and networks they will not all be suitable for the prediction of paleo communities. Some of these include the fact that the fossil record is incomplete/preservation is biased \[REF\] which means that we have an incomplete picture of the entire community. Fossils are 2D and only represent specific 'parts' of an individual (hard and bone-y bits), this means we don't have a complete picture of the physical traits of species *e.g.,* no body mass (but yes size), behaviours, or ability to construct well resolved phylogenetic trees the deeper we go back in time. Also owing to the patchy nature of fossils one often has to aggregate over large spatial scales, and also fossils are preserved in 2D so no *real* idea of spatial arrangements, compounded that fossils aren't necessarily conserved/found 'in situ' but can be moved (*e.g.,* alluvial deposits). Methodologically speaking some tools that 'learn' from contemporary communities (*e.g.,* Strydom, Caron) will become 'worse' the further one goes back in time since species then look very different from now but can still be useful for 'recent' communities (*e.g.,* fricke).

# Dataset Overview

-   Species

-   Time/space

-   And probably some other paleo things that will be relevant...

# Methods to use

**Paleo food web inference model** (PFIM; @shaw2024): uses a series of rules for a set of trait categories (such as habitat and body size) to determine if an interaction can feasibly occur between a species pair. If all conditions are met for the different rule classes then an interaction is deemed to be feasible. The original work put forward in @shaw2024 also includes a 'downsampling' step developed by @roopnarine2006 that uses a power law, defined by the link distribution, to 'prune' down some of the links.

**Allometric diet breadth model** (ADBM; @petchey2008): The ADBM is rooted in feeding theory and allocates the links between species based on energetics, which predicts the diet of a consumer based on energy intake. This means that the model is focused on predicting not only the number of links in a network but also the arrangement of these links based on the diet breadth of a species, where the diet ($K$) is defined as follows:

$$
K = \frac{\sum_{i=1}^{k}\lambda_{ij}E_{i}}{1+\sum_{i=1}^{k}\lambda_{ij}H_{ij}}
$$ {#eq-adbm}

where $\lambda_{ij}$ is the handling time, which is the product of the attack rate $A_{i}$ and resource density $N_{i}$, $E_{i}$ is the energy content of the resource and $H_{ij}$ is the ratio handling time, with the relationship being dependent on the ratio of predator and prey bodymass as follows:

$$
H_{ij} = \frac{h}{b - \frac{M_{i}}{M_{j}}} if \frac{M_{i}}{M_{j}} < b
$$

or

$$
H_{ij} = \infty \geq b
$$

Refer to @petchey2008 for more details as to how these different terms are parametrised.

**Body size ratio model** [@rohr2010]: Determines feeding interactions using the ratio between consumer and resource body sizes - which supposedly stems from niche theory (still trying to reconcile that myself). The probability of a link existing between a consumer and resource (in its most basic form) is defined as follows:

$$
P_{ij} = \frac{p}{1+p}
$$

where

$$
p = exp[\alpha + \beta log(\frac{M_{i}}{M_{j}}) + \gamma log^{2}(\frac{M_{i}}{M_{j}})]
$$ {#eq-bodymass}

The original latent-trait model developed by @rohr2010 also included an additional latent trait term $v_{i} \delta f_{j}$ however for simplicity we will use @eq-bodymass as per @yeakel2014 Based on @rohr2010 it is possible to estimate the parameters $\alpha$, $\delta$, and $\gamma$ using a GLM but we will use the parameters from @yeakel2014, which was 'trained' on the Serengeti food web data and are as follows: $\alpha = 1.41$, $\delta = 3.75$, and $\gamma = 1.87$.

**Niche model** [@williams2000]: The niche model introduces the idea that species interactions are based on the 'feeding niche' of a species. Broadly, all species are randomly assigned a 'feeding niche' range and all species that fall in this range can be consumed by that species (thereby allowing for cannibalism). The niche of each species is randomly assigned and the range of each species' niche is (in part) constrained by the specified connectance of the network. The niche model has also been modified, although it appears that adding to the 'complexity' of the niche model does not improve on its ability to generate a more ecologically 'correct' network [@williams2008].

# Results

## Comparing predicted networks

![stuff](figures/summary.png){#fig-summary}

## Comparing inference

## Extinctions

![Dashed line indicates the (mean) extinction simulation results (post value, start values are those estimated by the relevant model)](figures/extinction.png){#fig-extinction}

![Dark line indicates mean extinction simulation results the lighter lines show each model individually, which is also denoted by linetype](figures/extinction_all_results.png){#fig-extinction}

# References {.unnumbered}

::: {#refs}
:::